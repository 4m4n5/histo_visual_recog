{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastai.callbacks.hooks import *\n",
    "from fastai.callback import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_learner_init(PATH, sz, tfms, normalize_stats, model_load_name):\n",
    "    data = ImageDataBunch.from_folder(PATH, ds_tfms=tfms, size=sz)\n",
    "    data.normalize(normalize_stats)\n",
    "    print('Data Loaded and Normalized')\n",
    "    \n",
    "    learn = cnn_learner(data, models.resnet101, metrics=accuracy)\n",
    "    print('Model initialized')\n",
    "    if model_load_name:\n",
    "        learn.load('unfreeze101-epoch-1-meanstdnorm')\n",
    "        print('Moel loaded')\n",
    "    \n",
    "    return data, learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/project/DSone/as3ek/data/patches/1000/gannorm_seem_cinn_256/\"\n",
    "sz = 256\n",
    "tfms = get_transforms(do_flip=True, flip_vert=True, max_zoom=1.1)\n",
    "normalize_stats = data.batch_stats()\n",
    "model_load_name = 'unfreeze101-epoch-1-meanstdnorm' # False if none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, learn = data_learner_init(PATH, sz, tfms, normalize_stats, model_load_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "losses,idxs = interp.top_losses()\n",
    "len(data.valid_ds)==len(losses)==len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_output (module:nn.Module, detach:bool=True, grad:bool=False)->Hook:\n",
    "    \"Return a `Hook` that stores activations of `module` in `self.stored`\"\n",
    "    return Hook(module, _hook_inner, detach=detach, is_forward=not grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learn.model.eval()\n",
    "im,cl = learn.data.dl().dataset[1]\n",
    "cl = int(cl)\n",
    "xb,_ = data.one_item(im, detach=False, denorm=False, cpu=False) #put into a minibatch of batch size = 1\n",
    "\n",
    "with hook_output(m[0]) as hook_a: \n",
    "    with hook_output(m[0], grad=True) as hook_g:\n",
    "        preds = m(xb)\n",
    "        preds[0,int(cl)].backward() \n",
    "acts  = hook_a.stored[0].cpu() #activation maps\n",
    "if (acts.shape[-1]*acts.shape[-2]) >= 16:\n",
    "    grad = hook_g.stored[0][0].cpu()\n",
    "    grad_chan = grad.mean(1).mean(1)\n",
    "    mult = F.relu(((acts*grad_chan[...,None,None])).sum(0))\n",
    "    if True:\n",
    "        xb_im = Image(xb[0])\n",
    "        _,ax = plt.subplots()\n",
    "        sz = list(xb_im.shape[-2:])\n",
    "        xb_im.show(ax)\n",
    "        ax.imshow(mult, alpha=0.4, extent=(0,*sz[::-1],0),\n",
    "          interpolation='bilinear', cmap='magma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.normalize(data.batch_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.batch_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean((data.one_batch()[0] - torch.Tensor([0.7406, 0.5687, 0.6999])[...,None,None]) / torch.Tensor([0.1947, 0.2706, 0.1987])[...,None,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor([0.485, 0.456, 0.406])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denormalize(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
